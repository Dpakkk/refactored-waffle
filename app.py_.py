# -*- coding: utf-8 -*-
"""DS_Email_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DNO8PVryQsA8C7nqw9g47gwJqBFWTF5g
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline 
import math

import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/petersam/EmailClassification/main/spam_or_not_spam%20(1).csv")



#df.isnull()

#df.isnull().sum()

#dropping all the null values
#df.dropna()

#df.isnull().sum()

"""-----------------------------------------------------------------------------------------------------------------"""

df = pd.read_csv("https://raw.githubusercontent.com/petersam/EmailClassification/main/spam_or_not_spam%20(1).csv")

df



!pip install simplemma

import warnings
warnings.filterwarnings("ignore")

import re

import simplemma

from spacy.lang.en import English

langdata = dict()
langdata['en'] = simplemma.load_data('en')   

nlp = English()
lang = langdata.get('en')

def no_html(raw_text):
    
    no_html = raw_text.lower().strip()

    # remove urls
    no_html = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+').sub(r'', no_html)
    no_html = re.sub('www.*.(com|hr)', '', no_html)
    
    # remove emoji
    no_html = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE).sub(r'', no_html)

    # remove quotations, re: fw: and aw:
    no_html = re.sub('"', ' ', no_html)
    no_html = re.sub("'", ' ', no_html)
   
    no_html = re.sub('re:|fw:|aw:', ' ', no_html)



    no_html = re.sub("from:.*", '', no_html)


    # remove special symbols, incorrect words and numbers
    no_html = re.compile('[/(){}\[\]<>\|@,;_â€“.?!-*]').sub(' ', no_html)
    no_html = re.compile('[\d+]').sub(' ', no_html)
    no_html = re.sub(":", ' ', no_html)
    no_html = re.sub("-", ' ', no_html)
    no_html = re.sub(r'\s+',' ', no_html)
    no_html = no_html.strip()
    
    
    return no_html



def process_text_with_original(no_html):
    if no_html is None:
        return None

    # Second version (returns a string)
    cleaned_doc = [simplemma.lemmatize(token.text, lang).lower() for token in nlp(no_html) if len(token.text) > 1 and not token.is_stop and not token.is_punct and token.is_alpha]
    cleaned_doc = ' '.join(cleaned_doc)

    return cleaned_doc

df['email'] = df['email'].apply(str)

df['email'] = df['email'].map(no_html)

from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
stop = stopwords.words('english')

df['email'] = df['email'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

df





from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, chi2
import xgboost as xgb
from sklearn.model_selection import KFold, GridSearchCV
from sklearn.metrics import accuracy_score, make_scorer
from sklearn.model_selection import RandomizedSearchCV

X_train, X_test, y_train, y_test = train_test_split(df['email'], df['label'], random_state = 101, test_size= 0.2,stratify=df['label'],shuffle=True)

search_space = [
  {
    'clf__n_estimators': [50, 100, 150, 200],
    'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],
    'clf__max_depth': range(3, 10),
    'clf__colsample_bytree': [i/10.0 for i in range(1, 3)],
    'clf__gamma': [i/10.0 for i in range(3)],
    'fs__score_func': [chi2],
    'fs__k': [10],
  }
]

kfold = KFold(n_splits=10, random_state=42, shuffle=True)

# AUC and accuracy as score
scoring = {'AUC':'roc_auc', 'Accuracy':make_scorer(accuracy_score)}

count_vect = CountVectorizer()
tfidf_transformer = TfidfTransformer()

X_train_counts = count_vect.fit_transform(X_train)
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)

X_test_counts = count_vect.transform(X_test)
X_test_tfidf = tfidf_transformer.transform(X_test_counts)

xgboost_model = xgb.XGBClassifier()

xgboost_grid = RandomizedSearchCV(
  xgboost_model,
  param_distributions=search_space,
  cv=kfold,
  scoring=scoring,
  refit='AUC',
  verbose=1,
  n_jobs=-1
)

from sklearn.utils import class_weight
classes_weights = class_weight.compute_sample_weight(
    class_weight='balanced',
    y=X_train
)

classes_weights

model_xgboost_weights = xgboost_grid.fit(X_train_tfidf, y_train, sample_weight=classes_weights)

xgboost_predict_weights = model_xgboost_weights.predict(X_test_tfidf)

from sklearn.metrics import classification_report

print('accuracy %s' % accuracy_score(xgboost_predict_weights, y_test))
print(classification_report(y_test, xgboost_predict_weights))

from sklearn.svm import SVC

param_grid_svm = {'C': [0.1, 1, 10, 100, 1000],
              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
              'kernel': ['rbf']}

count_vect_svm = CountVectorizer()
tfidf_transformer_svm = TfidfTransformer()

X_train_counts_svm = count_vect_svm.fit_transform(X_train)
X_train_tfidf_svm = tfidf_transformer_svm.fit_transform(X_train_counts_svm)

X_test_counts_svm = count_vect_svm.transform(X_test)
X_test_tfidf_svm = tfidf_transformer_svm.transform(X_test_counts_svm)

svm_model_balanced = SVC(class_weight='balanced')
svm_model = SVC()

grid_svm_balanced = RandomizedSearchCV(
  svm_model_balanced,
  param_distributions=param_grid_svm,
  cv=kfold,
  scoring=scoring,
  refit='AUC',
  verbose=1,
  n_jobs=-1
)

grid_svm = RandomizedSearchCV(
  svm_model,
  param_distributions=param_grid_svm,
  cv=kfold,
  scoring=scoring,
  refit='AUC',
  verbose=1,
  n_jobs=-1
)

model_svm_weights = grid_svm_balanced.fit(X_train_tfidf_svm, y_train)

svm_predict_weights = model_svm_weights.predict(X_test_tfidf_svm)

from sklearn.metrics import classification_report

print('accuracy %s' % accuracy_score(svm_predict_weights, y_test))
print(classification_report(y_test, svm_predict_weights))



